{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_parquet(\"./data/66-test-dataset-with-adrd.parquet\")\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_array = test_df.Question.to_list()\n",
    "\n",
    "print(question_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CaLM-ADRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test.evaluation import call_api_batch\n",
    "\n",
    "answer_array = await call_api_batch(question_array)\n",
    "\n",
    "print(answer_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:, \"adrd_qwen3_14b\"] = answer_array\n",
    "\n",
    "test_df.to_parquet(\"./data/66-test-dataset-with-adrd.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_df = pd.read_parquet(\"./data/66-test-dataset-with-adrd.parquet\")\n",
    "\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From OpenAI GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "o3 = init_chat_model(\"o3-mini\", model_provider=\"openai\", temperature=1)\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "You are a compassionate healthcare consultant specializing in caregiving for Alzheimer's Disease and Related Dementias\n",
    "(ADRD). Your job is to provide empathetic, knowledgeable, and structured support to caregivers facing emotional,\n",
    "practical, and medical challenges. You answer questions based on the provided context (user's input and chat history)\n",
    "while offering responses that are warm, informative, and actionable.\n",
    "\n",
    "\n",
    "# Thinking Process\n",
    "\n",
    "Think step by step, but only keep a minimum draft for each thinking step, with 5 words at most.\n",
    "\n",
    "# Approach\n",
    "\t•\tAnswer starts with a paragraph (2-3 sentences) of introduction and emotional recognition and support, then answer the question in a structured way, and ends with a paragraph (2-3 sentences) of conclusion.\n",
    "\t•\tWarm yet professional: Speak with kindness, avoiding overly clinical or detached language.\n",
    "\t•\tNon-judgmental & supportive: Caregiving is challenging—reassure the user that they are doing their best.\n",
    "\t•\tUse proper in text citations to reference the sources and support your statements. In format of \"[<index>]\" (e.g. \"[1]\", \"[2]\", \"[3]\", etc.).\n",
    "\n",
    "# Context\n",
    "\n",
    "The caregiver's current query:\n",
    "{question}\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "chain = prompt | o3\n",
    "\n",
    "chain.invoke({\"question\": \"Hello, how are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "res_list = []\n",
    "\n",
    "for idx, question in enumerate(question_array):\n",
    "    response: BaseMessage = chain.invoke({\"question\": question})\n",
    "\n",
    "    res_list.append(response.content)\n",
    "    print(f\"Processed {idx} questions\")\n",
    "\n",
    "print(res_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:, \"gpt-o3\"] = res_list\n",
    "\n",
    "test_df.to_parquet(\"./data/66-test-dataset-with-adrd.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
